{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kMCn52hDeNF"
   },
   "source": [
    "# Superface Agent Hub - Open AI Function Calling Example\n",
    "In this notebook we demonstrate how to use the Superface Agent Hub to connect your OpenAI powered agent to external tools and APIs in a way that allows for both personal and third-party use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9gsOeblMhm1j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-server 1.11.0 requires anyio<4,>=3.1.0, but you have anyio 4.3.0 which is incompatible.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "12W1L6n1h5Z7"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import requests as r\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Set a random number of your choice, but don't change it\n",
    "# once you have run the notebook, otherwise you will create another user.\n",
    "SUPERFACE_USER_ID_CONSTANT = \n",
    "\n",
    "# Use the number to create a unique ID\n",
    "SUPERFACE_USER_ID = \"sfoaidemo|\" + str(SUPERFACE_USER_ID_CONSTANT)\n",
    "\n",
    "# Default URL for Superface\n",
    "SUPERFACE_BASE_URL = \"https://pod.superface.ai/api/hub\"\n",
    "\n",
    "# Set the Superface authentication token\n",
    "SUPERFACE_AUTH_TOKEN=\"<your-superface-auth-token>\"\n",
    "\n",
    "# Set the OpenAI API Key\n",
    "OPENAI_API_KEY=\"<your-open-api-key>\"\n",
    "\n",
    "\n",
    "# OpenAI Config\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "GPT_MODEL = \"gpt-4-turbo-preview\"\n",
    "INIT_INSTRUCTIONS = \"\"\"\n",
    "You are a helpful assistant.\n",
    "Respond to the following prompt by using function_call and then summarize actions.\n",
    "Ask for clarification if a user request is ambiguous.\n",
    "Display the agent_hint from the response to the user if it is present.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "i4Ve_YBxEOlY"
   },
   "outputs": [],
   "source": [
    "# Helper function to return the tool function descriptors\n",
    "def get_superface_tools():\n",
    "  headers = {\"Authorization\": \"Bearer \"+ SUPERFACE_AUTH_TOKEN}\n",
    "  tools = r.get(SUPERFACE_BASE_URL + \"/fd\", headers=headers)\n",
    "  return tools.json()\n",
    "\n",
    "# Helper function to perform the action for all the functions.\n",
    "# This is the only API call required regardless of what the function is.\n",
    "def perform_action(tool_name=None, tool_body=None):\n",
    "  headers = {\"Authorization\": \"Bearer \"+ SUPERFACE_AUTH_TOKEN, \"x-superface-user-id\": SUPERFACE_USER_ID}\n",
    "  perform = r.post(SUPERFACE_BASE_URL + \"/perform/\" + tool_name, headers=headers, json=tool_body)\n",
    "  return json.dumps(perform.json())\n",
    "\n",
    "# Helper function for calling the OpenAI Chat Completions API\n",
    "def perform_chat_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
    "  try:\n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=messages,\n",
    "      tools=tools,\n",
    "      tool_choice=tool_choice,\n",
    "    )\n",
    "    return response\n",
    "  except Exception as e:\n",
    "    print(\"Unable to generate ChatCompletion response\")\n",
    "    print(f\"Exception: {e}\")\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JyvEKQqvSq9E"
   },
   "outputs": [],
   "source": [
    "# User prompt - The weather tool requires no authentication\n",
    "prompt = \"What is the weather in Prague?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "5zG-Lpbkld-A",
    "outputId": "9a109b34-5682-4449-a516-45b88a796b86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-99u9jr7AmC358uN6FtFYumvuf720A', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The current weather in Prague, Czech Republic is partly cloudy with a temperature of 13째C, and it feels like 13째C.', role='assistant', function_call=None, tool_calls=None))], created=1712147843, model='gpt-4-0125-preview', object='chat.completion', system_fingerprint='fp_a7daf7c51e', usage=CompletionUsage(completion_tokens=28, prompt_tokens=2314, total_tokens=2342))\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The current weather in Prague, Czech Republic is partly cloudy with a temperature of 13째C, and it feels like 13째C."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": INIT_INSTRUCTIONS})\n",
    "\n",
    "\n",
    "messages.append({\n",
    "  \"role\": \"user\",\n",
    "  \"content\": prompt\n",
    "})\n",
    "\n",
    "chat_response = perform_chat_request(\n",
    "  messages, tools=get_superface_tools()\n",
    ")\n",
    "\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "\n",
    "#assistant_message\n",
    "\n",
    "tool_calls = assistant_message.tool_calls\n",
    "\n",
    "if (assistant_message.tool_calls):\n",
    "  # Assistant wants to call a tool, run it\n",
    "\n",
    "  for tool_call in tool_calls:\n",
    "    function_name = tool_call.function.name\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    function_response = perform_action(function_name, function_args)\n",
    "    #print(function_response)\n",
    "\n",
    "    messages.append(\n",
    "      {\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"role\": \"tool\",\n",
    "        \"name\": function_name,\n",
    "        \"content\": function_response,\n",
    "      }\n",
    "    )\n",
    "\n",
    "    second_chat_response = perform_chat_request(messages, tools=get_superface_tools())\n",
    "    print(second_chat_response)\n",
    "\n",
    "    if second_chat_response.choices[0].message.content:\n",
    "      display(Markdown(second_chat_response.choices[0].message.content))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
